<!DOCTYPE html>
<html lang="en">
<head>
	<title>Talks - Ryota Tomioka @ TTI-C</title>
	<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="../all.css"/>
	<meta http-equiv="content-type" content="text-html; charset=UTF-8"/>
</head>
<body>
	<div class="content">
		<div class="nav">
			<ul>
			  <li><a href="../">Home</a></li>
			  <li><a href="../softwares/">Softwares</a></li>
			  <li>Talks</li>
			  <li><a href="../teaching/">Teaching</a></li>
			</ul>
		</div>
		<h1>Slides</h1>
		<h2>Slides in English</h2>
		<ul>
			<li><a href="tensor12kyoto.pdf">2014/3/18: Towards better computation-statistics trade-off in tensor decomposition</a> (@<a href="http://www.iip.ist.i.kyoto-u.ac.jp/member/trendsinML/doku.php?id=home">Trends in Machine Learning at Kyoto University</a>)</li>
			<li><a href="../teaching/dtuphd12/dtuphd12.pdf">2012/8/15: Convex Optimization: Old Tricks for New Problems</a> (@<a href="http://www.imm.dtu.dk/Forskning/ISP/Undervisning/02901_2012.aspx">PhD Summer Course at Technical University of Denmark</a>)</li>
			<li><a href="TomiokaIntro.pdf">2012/5/7: Introduction to Tensor Decomposition Methods</a> (@ Miyano Lab., Human Genome Center, Institute of Medical Science)</li>
			<li><a href="tensor12kyoto.pdf">2012/1/26: Statistical Performance of Convex Tensor Decomposition</a> (@Perspectives in Informatics 4B, Kyoto University)</li>
			<li><a href="../teaching/dtuphd11/dtuphd11.pdf">2011/8/26: Convex Optimization: Old Tricks for New Problems</a> (@<a href="http://www.imm.dtu.dk/Forskning/ISP/Undervisning/02901_2011.aspx">PhD Summer Course at Technical University of Denmark</a>)</li>
			<li><a href="tensor11berlin.pdf">2011/3/23: Estimation of low-rank tensors via convex optimization</a> (@TU Berlin)</li>
			<li><a href="tomioka-mklworkshop10.pdf">2010/12/11: Regularization Strategies and Empirical Bayesian Learning for MKL</a> <a href="http://videolectures.net/nipsworkshops2010_tomioka_rse/">[Video]</a> (@<a href="http://doc.ml.tu-berlin.de/mkl_workshop/">NIPS2010 Workshop: New Directions in Multiple Kernel Learning</a></li>
			<li><a href="trace10.pdf">2010/12/10: On the Extension of Trace Norm to Tensors</a> (@<a href="http://csmr.ca.sandia.gov/~dfgleic/tkml2010/">NIPS2010 Workshop: Tensors, Kernels, and Machine Learning</a>)</li>
			<li><a href="icml10talk.pdf">2010/6/22: A Fast Augmented Lagrangian Algorithm for Learning Low-Rank Matrices</a> (@ICML2010)</li>
			<li><a href="opt09talk.pdf">2009/12/12: Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparse Learning</a> <a href="http://videolectures.net/nipsworkshops09_tomioka_slc/">[Video]</a> (@ NIPS Optimization Workshop 2009)</li>
			<li><a href="berlin09talk.pdf">2009/9/15: Dual Augmented Lagrangian, Proximal Minimization, and MKL</a></li>
			(@TU Berlin)
		</ul>
		<h2>Slides in Japanese</h2>
		<ul>
			<li><a href="tensor12handai.pdf">2012/11/30: 凸最適化に基づく テンソル分解アルゴリズム</a> @ 大阪大学ナノサイエンスデザイン教育研究センター</li>
			<li><a href="ramp11.pdf">2011/10/25: 機械学習における連続最適化の新しいトレンド</a> (@ <a href="http://www.dais.is.tohoku.ac.jp/~shioura/meeting/ramp2011/">RAMPシンポジウム 2011</a>)</li>
			<li><a href="nectalk11.pdf">2011/1/20: 機械学習における連続最適化の新しいトレンド</a> (@ <a href="http://www.nec.co.jp/rd/datamining/project/project1.html#project1-15">NEC データマイニングセミナー</a>)</li>
			<li><a href="icml10yomikai_tomioka.pdf">2010/8/18: 低ランク行列の学習のための速い拡張ラグランジュ法</a> (@ICML 2010読み会)</li>
			<li><a href="tokei-rinkou10.pdf">2010/4/13: Dual Augmented Lagrangian Algorithm 法による スパース正則化</a>（＠統計学輪講）</li>
			<li><a href="../softwares/prmu09/">2009/8/31: MATLABによるスパース正則化／信号復元のデモンストレーション</a> (PRMU/CVIM 仙台) <a href="http://translate.google.co.jp/translate?js=y&hl=en&u=http://ttic.uchicago.edu/~ryotat/softwares/prmu09/&sl=ja&tl=en">[English translation]</a></li>
		</ul>
	</div>
</body>
</html>
